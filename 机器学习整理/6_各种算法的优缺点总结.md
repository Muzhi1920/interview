<!-- TOC -->

1. [各种机器学习算法优缺点总结](#各种机器学习算法优缺点总结)
   1. [决策树](#决策树)
      1. [决策树优点](#决策树优点)
      2. [决策树缺点](#决策树缺点)
      3. [改进措施](#改进措施)
      4. [C4.5算法](#c45算法)
         1. [优点：](#优点)
         2. [缺点：](#缺点)
      5. [CART分类与回归树](#cart分类与回归树)
         1. [优点：](#优点-1)
      6. [随机森林](#随机森林)
   2. [K-Means聚类](#k-means聚类)
   3. [EM算法](#em算法)
   4. [LR](#lr)
   5. [朴素贝叶斯](#朴素贝叶斯)
   6. [SVM](#svm)
   7. [集成算法（AdaBoost算法）](#集成算法adaboost算法)
      1. [AdaBoost算法优点](#adaboost算法优点)
      2. [Adaboost算法缺点](#adaboost算法缺点)
   8. [神经网络](#神经网络)
   9. [隐马尔可夫HMM](#隐马尔可夫hmm)
   10. [CRF条件随机场](#crf条件随机场)

<!-- /TOC -->
<a id="markdown-各种机器学习算法优缺点总结" name="各种机器学习算法优缺点总结"></a>
# 各种机器学习算法优缺点总结

<a id="markdown-决策树" name="决策树"></a>
## 决策树
>>可回归，可分类

<a id="markdown-决策树优点" name="决策树优点"></a>
### 决策树优点
1. 决策树易于理解和解释，可以可视化分析，容易提取出规则。
2. 可以同时处理标称型和数值型数据。
3. 测试数据集时，运行速度比较快。
4. 决策树可以很好的扩展到大型数据库中，同时它的大小独立于数据库大小。

<a id="markdown-决策树缺点" name="决策树缺点"></a>
### 决策树缺点
1. 对缺失数据处理比较困难。
2. 容易出现过拟合问题。
3. 忽略数据集中属性的相互关联。
4. ID3算法计算信息增益时结果偏向数值比较多的特征。

<a id="markdown-改进措施" name="改进措施"></a>
### 改进措施
剪枝，采用交叉验证法，加入正则化；bagging算法，randomforest算法，可以解决过拟合的问题。

<a id="markdown-c45算法" name="c45算法"></a>
### C4.5算法
C4.5算法核心思想是ID3算法的改进，改进方面有：
1. 用信息增益率来选择属性，克服了用信息增益选择属性时偏向选择取值多的属性的不足；
2. 在树构造过程中进行剪枝；
3. 能处理非离散的数据；
4. 能处理不完整的数据。
<a id="markdown-优点" name="优点"></a>
#### 优点：
产生的分类规则易于理解，准确率较高。
<a id="markdown-缺点" name="缺点"></a>
#### 缺点：
1. 在构造树的过程中，需要对数据集进行多次的顺序扫描和排序，因而导致算法的低效；
2. C4.5只适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时程序无法运行。

<a id="markdown-cart分类与回归树" name="cart分类与回归树"></a>
### CART分类与回归树
<a id="markdown-优点-1" name="优点-1"></a>
#### 优点：
1. 非常灵活，可以允许有部分错分成本，还可指定先验概率分布，可使用自动的成本复杂性剪枝来得到归纳性更强的树。
2. 在面对诸如存在缺失值、变量数多等问题时CART 显得非常稳健。
<a id="markdown-随机森林" name="随机森林"></a>
### 随机森林
- 优点：不易过拟合，并行化更快；降方差；鲁棒性更强；适用大规模数据和不相关特征
- 准确度可能不够；噪声较大的问题上会过拟合；内部级别较多的特征对模型影响更大，此时权值不可信；

<a id="markdown-k-means聚类" name="k-means聚类"></a>
## K-Means聚类
- 优点：复杂度O(N\*K\*T)，N样本数，K类别数，T迭代数
- 缺点：对噪声孤立点敏感；K的定义trick。

<a id="markdown-em算法" name="em算法"></a>
## EM算法

- 优点：含隐变量弥补极大似然缺陷；
- 缺点：迭代收敛慢，依赖初始化参数假设

<a id="markdown-lr" name="lr"></a>
## LR
- 优点：计算小，存储低；
- 缺点：欠拟合，精度不高；

<a id="markdown-朴素贝叶斯" name="朴素贝叶斯"></a>
## 朴素贝叶斯
>>使用先验知识，得到后验概率，条件独立性假设前提下，期望风险最小化得到后验概率最大化。
- 优点：小规模数据效果好，可以多分类；支持增量式运算。即可以实时的对新增的样本进行训练；可解释性强；
- 缺点：条件独立性假设，性能不一定高；

<a id="markdown-svm" name="svm"></a>
## SVM
- 优点：小样本下，可实现非线性分类，用于分类与回归，泛化能力强；无局部极小值问题，可以很好的处理高维数据集。
- 缺点：对核函数和参数敏感；对于核函数的高维映射解释力不强，尤其是径向基函数；对缺失数据敏感。


<a id="markdown-集成算法adaboost算法" name="集成算法adaboost算法"></a>
## 集成算法（AdaBoost算法）
<a id="markdown-adaboost算法优点" name="adaboost算法优点"></a>
### AdaBoost算法优点
1. 很好的利用了弱分类器进行级联。
2. 可以将不同的分类算法作为弱分类器。
3. AdaBoost具有很高的精度。
4. 相对于bagging算法和Random Forest算法，AdaBoost充分考虑的每个分类器的权重。

<a id="markdown-adaboost算法缺点" name="adaboost算法缺点"></a>
### Adaboost算法缺点
1. AdaBoost迭代次数也就是弱分类器数目不太好设定，可以使用交叉验证来进行确定。
2. 数据不平衡导致分类精度下降。
3. 训练比较耗时，每次重新选择当前分类器最好切分点。

<a id="markdown-神经网络" name="神经网络"></a>
## 神经网络
- 优点：非线性拟合能力强；鲁棒性强；并行性好；
- 缺点：可解释性差，初值敏感；

<a id="markdown-隐马尔可夫hmm" name="隐马尔可夫hmm"></a>
## 隐马尔可夫HMM
- 优点：解决标注问题；
- 缺点：齐次马尔科夫假设与观测孤立性假设，可能出现标记偏置。

<a id="markdown-crf条件随机场" name="crf条件随机场"></a>
## CRF条件随机场
- 优点：全局范围最优解；解决MEMM标注偏置；没有条件独立性假设；计算整个标记序列的联合概率分布；
- 缺点：训练代价大，复杂度高。

