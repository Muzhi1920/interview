<!-- TOC -->

- [大数据要点整理](#%e5%a4%a7%e6%95%b0%e6%8d%ae%e8%a6%81%e7%82%b9%e6%95%b4%e7%90%86)
  - [一、Spark](#%e4%b8%80spark)
    - [1、Spark job资源分配](#1spark-job%e8%b5%84%e6%ba%90%e5%88%86%e9%85%8d)
    - [File,Block,Split,Task,Partition,RDD,Node,Executors,Cores](#fileblocksplittaskpartitionrddnodeexecutorscores)
  - [二、Hadoop](#%e4%ba%8chadoop)
    - [1. MapReduce](#1-mapreduce)
    - [2. Partition](#2-partition)
    - [3. Combiner](#3-combiner)
    - [4. 二次排序](#4-%e4%ba%8c%e6%ac%a1%e6%8e%92%e5%ba%8f)
  - [三、Hive](#%e4%b8%89hive)
    - [Hive与SQL](#hive%e4%b8%8esql)
  - [四、Kafka](#%e5%9b%9bkafka)
  - [五、Flink](#%e4%ba%94flink)
    - [流处理与批处理](#%e6%b5%81%e5%a4%84%e7%90%86%e4%b8%8e%e6%89%b9%e5%a4%84%e7%90%86)
      - [Flink容错性高，快照恢复](#flink%e5%ae%b9%e9%94%99%e6%80%a7%e9%ab%98%e5%bf%ab%e7%85%a7%e6%81%a2%e5%a4%8d)

<!-- /TOC -->


# 大数据要点整理
Apache Storm、Apache Smaza只支持流处理任务；Aapche MapReduce、Apache Tez、Apache Spark只支持批处理任务。Spark Streaming是Apache Spark之上支持流处理任务的子系统，实际上Spark Streaming采用了一种micro-batch的架构，即把输入的数据流切分成细粒度的batch，并为每一个batch数据提交一个批处理的Spark任务，所以Spark Streaming本质上还是基于Spark批处理系统对流式数据进行处理，和Apache Storm、Apache Smaza等完全流式的数据处理方式完全不同。通过其灵活的执行引擎，Flink能够同时支持批处理任务与流处理任务。

---
## 一、Spark
### 1、Spark job资源分配

|config|num|annotation|
|--------|--------|--------|
|driver-memory	|4g	|driver使用的内存，不可超过单机的 core 总数。
|num-executors	|2 |创建多少个 executor。
|executor-memory	|2g	|各个 executor使用的最大内存，不可超过单机的最大可使用内存。
|executor-cores	|2	|各个 executor 使用的并发线程数目，也即每个 executor 最大可并发执行的 Task 数目。
![avatar](img/cluster.jpg)
- 数据倾斜：某个key下value过多，reduce_task处理任务过重导致运行特别慢。shuffle出现在期间。造成后果：有得任务执行完毕，某个任务执行很慢而且可能出现OOM错误；一般增大执行器与核数，并行数，自定义partition

- 尽量减少spark任务的空间占用，同时加速spark任务运行速度

### File,Block,Split,Task,Partition,RDD,Node,Executors,Cores
![](img/spark.png)
- 本文件内若干个Block合并成一个输入分片split；不能跨越文件；
- 一个split对应一个Task；
- 一个Task执行结果对应RDD的partition**增大分区数，增大task数，增大并行度**
- 一个Executor数目包含多个core；


## 二、Hadoop
### 1. MapReduce
![avatar](https://images2018.cnblogs.com/blog/1001760/201802/1001760-20180228124848632-694325369.png)
![avatar](img/mr.jpg)
map task读取文件写入环形缓冲区（100M），一次溢出后按照key进行hash分区，多次溢出的文件按照分区合并(归并排序)；对多个map task的相同分区内的key进行归并排序，然后传给reduce task。

### 2. Partition
map端输出(k,v)对key取hash值实现分区负载均衡算法

### 3. Combiner
每一个map都可能会产生大量的本地输出，Combiner的作用就是对**本地的map端的输出先做一次合并**key下value以list形式存储，**大大减少在map和reduce节点之间的数据传输量，以提高网络IO性能**是MapReduce的一种优化手段之一。就在part下对相同的key提前合并一下

### 4. 二次排序
如何做到在Reduce阶段，先对Key排序，再对Value排序
该问题通常称为”二次排序“，最常用的方法是将Value放到Key中，实现一个组合Key，然后自定义Key排序规则（为Key实现一个WritableComparable）


## 三、Hive
```sql
#以某字符连接字段
concat_ws：SELECT CONCAT_WS('_',id,name) AS con_ws FROM info;
#对字段A分组，队字段B降序且取字段B的top3
row_number：select id,age,name,sex from
(select id,age,name,sex,row_number() over(partition by sex order by age desc) as rownumber from rownumber) temp where rownumber<3 
#条件真值与假值
case..when：case tb1.os when 'android' then 'android' when 'ios' then 'iPhone' else 'PC' end as os
##[{"name":"王二狗","sex":"男","age":"25"},{"name":"李狗嗨","sex":"男","age":"47"}]
get_json_object：
1.SELECT get_json_object(xjson,"$.[0]") FROM person;
2.SELECT get_json_object(xjson,"$.[0].age") FROM person;
```

### Hive与SQL
- 数据存储位置不同：hive是把数据存储在hdfs上，mysql数据是存储在自己的系统中
- 数据格式：hive数据格式用户可以自定义，mysql有自己的系统定义格式
- 数据更新：hive不支持数据更新，只可以读，不可以写，而sql支持数据更新
- 索引：hive没有索引，因此查询数据的时候是通过mapreduce很暴力的把数据都查询一遍，也造成了hive查询数据速度很慢的原因，而mysql有索引；
- 延迟性：hive延迟性高，原因就是上边一点所说的，而mysql延迟性低；
- 数据规模：hive存储的数据量超级大，而mysql只是存储一些少量的业务数据；
- 底层执行原理：hive底层是用的mapreduce，而mysql是excutor执行器

## 四、Kafka
消息是kafka主要处理的对象，在某个主题之下，生产者向主题发布新消息，消费者从主题订阅新消息。
异步处理、应用解耦、流量缓冲、日志采集
- 消息队列实现订单系统与库存系统的解耦，到应用层的解耦，防止短时间压垮应用；
- 负责日志数据接收存储与转发

## 五、Flink
### 流处理与批处理
1. 流处理系统：一条数据被处理完成后，序列化到缓存中，通过网络传输到下一个节点，由下一个节点继续处理。
2. 批处理系统：一条数据被处理完成后，序列化到缓存中，并不会立刻通过网络传输到下一个节点，当缓存写满，就持久化到本地硬盘上，当所有数据都被处理完成后，才数据通过网络传输到下一个节点。

- 数据传输的两个极端：流处理系统对低延迟；批处理系统对高吞吐量。
- **Flink是两个极端的折中，以固定缓存块为单位传输，且缓存块超时值是可调的**。如果缓存块为0，则是低延迟的流处理系统；如果缓存块的超时值为无限大，则是高吞吐量的批处理系统。

#### Flink容错性高，快照恢复
Flink基于分布式快照与可部分重发的数据源实现了容错。用户可自定义对整个Job进行快照的时间间隔，当任务失败时，Flink会将整个Job恢复到最近一次快照，并从数据源重发快照之后的数据。

