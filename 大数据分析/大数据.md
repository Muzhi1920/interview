# 大数据要点整理
Apache Storm、Apache Smaza只支持流处理任务；Aapche MapReduce、Apache Tez、Apache Spark只支持批处理任务。Spark Streaming是Apache Spark之上支持流处理任务的子系统，实际上Spark Streaming采用了一种micro-batch的架构，即把输入的数据流切分成细粒度的batch，并为每一个batch数据提交一个批处理的Spark任务，所以Spark Streaming本质上还是基于Spark批处理系统对流式数据进行处理，和Apache Storm、Apache Smaza等完全流式的数据处理方式完全不同。通过其灵活的执行引擎，Flink能够同时支持批处理任务与流处理任务。

---
## 一、Spark
### 1、Spark job资源分配

|config|num|annotation|
|--------|--------|--------|
|driver-memory	|4g	|driver使用的内存，不可超过单机的 core 总数。
|num-executors	|2 |创建多少个 executor。
|executor-memory	|2g	|各个 executor使用的最大内存，不可超过单机的最大可使用内存。
|executor-cores	|2	|各个 executor 使用的并发线程数目，也即每个 executor 最大可并发执行的 Task 数目。
![avatar](img/cluster.jpg)
- 数据倾斜：某个key下value过多，reduce_task处理任务过重导致运行特别慢。shuffle出现在期间。造成后果：有得任务执行完毕，某个任务执行很慢而且可能出现OOM错误；一般增大执行器与核数，并行数，自定义partition

- 尽量减少spark任务的空间占用，同时加速spark任务运行速度

## 二、Hadoop
1. MapReduce
![avatar](https://images2018.cnblogs.com/blog/1001760/201802/1001760-20180228124848632-694325369.png)

2. Partition
>>map端输出(k,v)对key取hash值实现分区负载均衡算法

3. Combiner
>>每一个map都可能会产生大量的本地输出，Combiner的作用就是对**本地的map端的输出先做一次合并**key下value以list形式存储，**大大减少在map和reduce节点之间的数据传输量，以提高网络IO性能**是MapReduce的一种优化手段之一。


## 三、Hive
```sql
#以某字符连接字段
concat_ws：SELECT CONCAT_WS('_',id,name) AS con_ws FROM info;
#对字段A分区，取字段B的top3
row_number：select id,age,name,sex from
(select id,age,name,sex,row_number() over(partition by sex order by age desc) as rownumber from rownumber) temp where rownumber<3 
#条件真值与假值
case..when：case tb1.os when 'android' then 'android' when 'ios' then 'iPhone' else 'PC' end as os
##[{"name":"王二狗","sex":"男","age":"25"},{"name":"李狗嗨","sex":"男","age":"47"}]
get_json_object：
1.SELECT get_json_object(xjson,"$.[0]") FROM person;
2.SELECT get_json_object(xjson,"$.[0].age") FROM person;
```
### Hive与SQL
- 数据存储位置不同：hive是把数据存储在hdfs上，mysql数据是存储在自己的系统中
- 数据格式：hive数据格式用户可以自定义，mysql有自己的系统定义格式
- 数据更新：hive不支持数据更新，只可以读，不可以写，而sql支持数据更新
- 索引：hive没有索引，因此查询数据的时候是通过mapreduce很暴力的把数据都查询一遍，也造成了hive查询数据速度很慢的原因，而mysql有索引；
- 延迟性：hive延迟性高，原因就是上边一点所说的，而mysql延迟性低；
- 数据规模：hive存储的数据量超级大，而mysql只是存储一些少量的业务数据；
- 底层执行原理：hive底层是用的mapreduce，而mysql是excutor执行器

## 四、Kafka
消息是kafka主要处理的对象，在某个主题之下，生产者向主题发布新消息，消费者从主题订阅新消息。
异步处理、应用解耦、流量缓冲、日志采集
- 消息队列实现订单系统与库存系统的解耦，到应用层的解耦，防止短时间压垮应用；
- 负责日志数据接收存储与转发

## 五、Flink
1. 流处理系统：一条数据被处理完成后，序列化到缓存中，通过网络传输到下一个节点，由下一个节点继续处理。
2. 批处理系统，其节点间数据传输的标准模型是：当一条数据被处理完成后，序列化到缓存中，并不会立刻通过网络传输到下一个节点，当缓存写满，就持久化到本地硬盘上，当所有数据都被处理完成后，才开始将处理后的数据通过网络传输到下一个节点。

>>数据传输的两个极端：流处理系统对低延迟；批处理系统对高吞吐量。**Flink是两个极端的折中，以固定缓存块为单位传输，且缓存块超时值是可调的**。

如果缓存块为0，则是低延迟的流处理系统；如果缓存块的超时值为无限大，则是高吞吐量的批处理系统。
#### Flink容错性高，快照恢复
Flink基于分布式快照与可部分重发的数据源实现了容错。用户可自定义对整个Job进行快照的时间间隔，当任务失败时，Flink会将整个Job恢复到最近一次快照，并从数据源重发快照之后的数据。



