<!-- TOC -->

1. [大数据要点整理](#大数据要点整理)
   1. [一、Spark](#一spark)
      1. [1、Spark job资源分配](#1spark-job资源分配)
      2. [File,Block,Split,Task,Partition,RDD,Node,Executors,Cores](#fileblocksplittaskpartitionrddnodeexecutorscores)
   2. [二、Hadoop](#二hadoop)
      1. [1. MapReduce](#1-mapreduce)
      2. [2. Partition](#2-partition)
      3. [3. Combiner](#3-combiner)
      4. [4. 二次排序](#4-二次排序)
   3. [三、Hive](#三hive)
      1. [Hive与SQL](#hive与sql)
   4. [四、Kafka](#四kafka)
   5. [五、Flink](#五flink)
      1. [流处理与批处理](#流处理与批处理)
         1. [Flink容错性高，快照恢复](#flink容错性高快照恢复)

<!-- /TOC -->


<a id="markdown-大数据要点整理" name="大数据要点整理"></a>
# 大数据要点整理
Apache Storm、Apache Smaza只支持流处理任务；Aapche MapReduce、Apache Tez、Apache Spark只支持批处理任务。Spark Streaming是Apache Spark之上支持流处理任务的子系统，实际上Spark Streaming采用了一种micro-batch的架构，即把输入的数据流切分成细粒度的batch，并为每一个batch数据提交一个批处理的Spark任务，所以Spark Streaming本质上还是基于Spark批处理系统对流式数据进行处理，和Apache Storm、Apache Smaza等完全流式的数据处理方式完全不同。通过其灵活的执行引擎，Flink能够同时支持批处理任务与流处理任务。

---
<a id="markdown-一spark" name="一spark"></a>
## 一、Spark
<a id="markdown-1spark-job资源分配" name="1spark-job资源分配"></a>
### 1、Spark job资源分配

|config|num|annotation|
|--------|--------|--------|
|driver-memory	|4g	|driver使用的内存，不可超过单机的 core 总数。
|num-executors	|2 |创建多少个 executor。
|executor-memory	|2g	|各个 executor使用的最大内存，不可超过单机的最大可使用内存。
|executor-cores	|2	|各个 executor 使用的并发线程数目，也即每个 executor 最大可并发执行的 Task 数目。
![avatar](img/cluster.jpg)
- 数据倾斜：某个key下value过多，reduce_task处理任务过重导致运行特别慢。shuffle出现在期间。造成后果：有得任务执行完毕，某个任务执行很慢而且可能出现OOM错误；一般增大执行器与核数，并行数，自定义partition

- 尽量减少spark任务的空间占用，同时加速spark任务运行速度

<a id="markdown-fileblocksplittaskpartitionrddnodeexecutorscores" name="fileblocksplittaskpartitionrddnodeexecutorscores"></a>
### File,Block,Split,Task,Partition,RDD,Node,Executors,Cores
![](img/spark.png)
- 本文件内若干个Block合并成一个输入分片split；不能跨越文件；
- 一个split对应一个Task；
- 一个Task执行结果对应RDD的partition**增大分区数，增大task数，增大并行度**
- 一个Executor数目包含多个core；


<a id="markdown-二hadoop" name="二hadoop"></a>
## 二、Hadoop
<a id="markdown-1-mapreduce" name="1-mapreduce"></a>
### 1. MapReduce
![avatar](img/mr.png)
![avatar](img/mr.jpg)
map task读取文件写入环形缓冲区（100M），一次溢出后按照key进行hash分区，多次溢出的文件按照分区合并(归并排序)；对多个map task的相同分区内的key进行归并排序，然后传给reduce task。

<a id="markdown-2-partition" name="2-partition"></a>
### 2. Partition
map端输出(k,v)对key取hash值实现分区负载均衡算法

<a id="markdown-3-combiner" name="3-combiner"></a>
### 3. Combiner
每一个map都可能会产生大量的本地输出，Combiner的作用就是对**本地的map端的输出先做一次合并**key下value以list形式存储，**大大减少在map和reduce节点之间的数据传输量，以提高网络IO性能**是MapReduce的一种优化手段之一。就在part下对相同的key提前合并一下

<a id="markdown-4-二次排序" name="4-二次排序"></a>
### 4. 二次排序
如何做到在Reduce阶段，先对Key排序，再对Value排序
该问题通常称为”二次排序“，最常用的方法是将Value放到Key中，实现一个组合Key，然后自定义Key排序规则（为Key实现一个WritableComparable）


<a id="markdown-三hive" name="三hive"></a>
## 三、Hive
```sql
#以某字符连接字段
concat_ws：SELECT CONCAT_WS('_',id,name) AS con_ws FROM info;
#对字段A分组，队字段B降序且取字段B的top3
row_number：select id,age,name,sex from
(select id,age,name,sex,row_number() over(partition by sex order by age desc) as rownumber from rownumber) temp where rownumber<3 
#条件真值与假值
case..when：case tb1.os when 'android' then 'android' when 'ios' then 'iPhone' else 'PC' end as os
##[{"name":"王二狗","sex":"男","age":"25"},{"name":"李狗嗨","sex":"男","age":"47"}]
get_json_object：
1.SELECT get_json_object(xjson,"$.[0]") FROM person;
2.SELECT get_json_object(xjson,"$.[0].age") FROM person;
```

<a id="markdown-hive与sql" name="hive与sql"></a>
### Hive与SQL
- 数据存储位置不同：hive是把数据存储在hdfs上，mysql数据是存储在自己的系统中
- 数据格式：hive数据格式用户可以自定义，mysql有自己的系统定义格式
- 数据更新：hive不支持数据更新，只可以读，不可以写，而sql支持数据更新
- 索引：hive没有索引，因此查询数据的时候是通过mapreduce很暴力的把数据都查询一遍，也造成了hive查询数据速度很慢的原因，而mysql有索引；
- 延迟性：hive延迟性高，原因就是上边一点所说的，而mysql延迟性低；
- 数据规模：hive存储的数据量超级大，而mysql只是存储一些少量的业务数据；
- 底层执行原理：hive底层是用的mapreduce，而mysql是excutor执行器

<a id="markdown-四kafka" name="四kafka"></a>
## 四、Kafka
消息是kafka主要处理的对象，在某个主题之下，生产者向主题发布新消息，消费者从主题订阅新消息。
异步处理、应用解耦、流量缓冲、日志采集
- 消息队列实现订单系统与库存系统的解耦，到应用层的解耦，防止短时间压垮应用；
- 负责日志数据接收存储与转发

<a id="markdown-五flink" name="五flink"></a>
## 五、Flink
<a id="markdown-流处理与批处理" name="流处理与批处理"></a>
### 流处理与批处理
1. 流处理系统：一条数据被处理完成后，序列化到缓存中，通过网络传输到下一个节点，由下一个节点继续处理。
2. 批处理系统：一条数据被处理完成后，序列化到缓存中，并不会立刻通过网络传输到下一个节点，当缓存写满，就持久化到本地硬盘上，当所有数据都被处理完成后，才数据通过网络传输到下一个节点。

- 数据传输的两个极端：流处理系统对低延迟；批处理系统对高吞吐量。
- **Flink是两个极端的折中，以固定缓存块为单位传输，且缓存块超时值是可调的**。如果缓存块为0，则是低延迟的流处理系统；如果缓存块的超时值为无限大，则是高吞吐量的批处理系统。

<a id="markdown-flink容错性高快照恢复" name="flink容错性高快照恢复"></a>
#### Flink容错性高，快照恢复
Flink基于分布式快照与可部分重发的数据源实现了容错。用户可自定义对整个Job进行快照的时间间隔，当任务失败时，Flink会将整个Job恢复到最近一次快照，并从数据源重发快照之后的数据。

